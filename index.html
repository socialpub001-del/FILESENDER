 import React, { useState, useEffect, useRef, useCallback } from 'react';
import { 
  Sparkles, 
  ScanFace, 
  Camera, 
  MoveHorizontal, 
  Activity,
  Zap,
  Maximize
} from 'lucide-react';
import { initializeApp } from 'firebase/app';
import { 
  getAuth, 
  signInAnonymously, 
  onAuthStateChanged, 
  signInWithCustomToken 
} from 'firebase/auth';

// --- Firebase Configuration ---
const firebaseConfig = JSON.parse(__firebase_config);
const app = initializeApp(firebaseConfig);
const auth = getAuth(app);

// --- Gesture Control Hook (Enhanced with Visual Debugging) ---
function useMotionGestures(
  onGesture: (direction: 'left' | 'right') => void, 
  isActive: boolean,
  sensitivity: number,
  onStatsUpdate: (left: number, right: number) => void
) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null); // Low res analysis
  const debugCanvasRef = useRef<HTMLCanvasElement>(null); // Visual feedback overlay
  const lastFrameData = useRef<Uint8ClampedArray | null>(null);
  const rafId = useRef<number>();
  const cooldown = useRef(false);

  useEffect(() => {
    if (!isActive) {
      if (rafId.current) cancelAnimationFrame(rafId.current);
      return;
    }

    const startCamera = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 320, height: 240 } });
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.play();
        }
        processFrame();
      } catch (e) {
        console.error("Camera access denied", e);
      }
    };

    startCamera();

    return () => {
      if (rafId.current) cancelAnimationFrame(rafId.current);
      const stream = videoRef.current?.srcObject as MediaStream;
      stream?.getTracks().forEach(t => t.stop());
    };
  }, [isActive]);

  const processFrame = () => {
    if (!videoRef.current || !canvasRef.current || !debugCanvasRef.current) return;
    
    const ctx = canvasRef.current.getContext('2d');
    const debugCtx = debugCanvasRef.current.getContext('2d');
    if (!ctx || !debugCtx) return;

    // Draw video to low-res canvas for processing
    // We use a small grid (32x24) for performance and easier motion clustering
    const width = 32;
    const height = 24;
    ctx.drawImage(videoRef.current, 0, 0, width, height); 
    
    // Clear debug canvas
    debugCtx.clearRect(0, 0, debugCanvasRef.current.width, debugCanvasRef.current.height);

    const frame = ctx.getImageData(0, 0, width, height);
    const data = frame.data;
    const length = data.length;

    if (lastFrameData.current) {
      let leftMotion = 0;
      let rightMotion = 0;
      
      // Calculate motion
      for (let i = 0; i < length; i += 4) {
        // Compare Green channel (usually good for skin tones/contrast)
        const diff = Math.abs(data[i+1] - lastFrameData.current[i+1]);
        
        // Lower pixel threshold means it detects subtler movements
        // Was 20, now 15 to catch more light changes
        if (diff > 15) { 
          const x = (i / 4) % width;
          const y = Math.floor((i / 4) / width);

          // Draw debug dot on the high-res overlay
          // Scale 32x24 coordinates up to 320x240
          const drawX = x * 10;
          const drawY = y * 10;

          if (x < 12) {
             leftMotion++;
             debugCtx.fillStyle = "rgba(0, 255, 255, 0.5)"; // Cyan for Left
             debugCtx.fillRect(drawX, drawY, 10, 10);
          } else if (x > 20) {
             rightMotion++;
             debugCtx.fillStyle = "rgba(168, 85, 247, 0.5)"; // Purple for Right
             debugCtx.fillRect(drawX, drawY, 10, 10);
          }
        }
      }

      // Update UI stats (Boosted for visibility)
      onStatsUpdate(leftMotion * 2, rightMotion * 2);

      // Trigger Logic
      // Threshold calculation:
      // If Sensitivity = 100, Threshold = 10 (Very Easy)
      // If Sensitivity = 1, Threshold = 100 (Hard)
      const threshold = Math.max(5, 100 - sensitivity);

      if (!cooldown.current) {
        // Check if one side has significantly more motion than the other
        if (leftMotion > threshold && leftMotion > rightMotion * 1.5) {
           onGesture('right'); // Mirrored: Left Motion = Swipe Right (Previous)
           triggerCooldown();
        } else if (rightMotion > threshold && rightMotion > leftMotion * 1.5) {
           onGesture('left'); // Mirrored: Right Motion = Swipe Left (Next)
           triggerCooldown();
        }
      }
    }

    // Deep copy current frame to last frame
    lastFrameData.current = new Uint8ClampedArray(data);
    rafId.current = requestAnimationFrame(processFrame);
  };

  const triggerCooldown = () => {
    cooldown.current = true;
    setTimeout(() => cooldown.current = false, 800); // Faster reset
  };

  return { videoRef, canvasRef, debugCanvasRef };
}

export default function App() {
  const [user, setUser] = useState<any>(null);
  const [visionMode, setVisionMode] = useState(true);
  const [sensitivity, setSensitivity] = useState(80); // Default to High Sensitivity
  const [gestureFeedback, setGestureFeedback] = useState<'left' | 'right' | null>(null);
  const [motionStats, setMotionStats] = useState({ left: 0, right: 0 });

  useEffect(() => {
    const initAuth = async () => {
      if (typeof __initial_auth_token !== 'undefined' && __initial_auth_token) {
        await signInWithCustomToken(auth, __initial_auth_token);
      } else {
        await signInAnonymously(auth);
      }
    };
    initAuth();
    onAuthStateChanged(auth, u => setUser(u));
  }, []);

  const handleGesture = useCallback((direction: 'left' | 'right') => {
    setGestureFeedback(direction);
    if (navigator.vibrate) navigator.vibrate([30, 30, 30]); // Distinct vibration
    setTimeout(() => setGestureFeedback(null), 800);
  }, []);

  const { videoRef, canvasRef, debugCanvasRef } = useMotionGestures(
    handleGesture, 
    visionMode, 
    sensitivity, 
    (l, r) => setMotionStats({ left: l, right: r })
  );

  return (
    <div className="h-screen w-full bg-slate-950 text-cyan-400 font-mono flex flex-col overflow-hidden relative select-none">
      
      {/* Background Ambience */}
      <div className="absolute inset-0 bg-[radial-gradient(circle_at_50%_120%,#1e293b,transparent_80%)] pointer-events-none" />
      <div className="absolute inset-0 bg-[url('https://www.transparenttextures.com/patterns/stardust.png')] opacity-10 pointer-events-none animate-pulse" />

      {/* Navbar */}
      <header className="h-14 border-b border-cyan-900/40 bg-slate-900/60 backdrop-blur flex items-center justify-between px-6 z-20 shadow-[0_4px_20px_rgba(0,0,0,0.4)]">
        <div className="flex items-center gap-2">
           <Zap className="w-5 h-5 text-yellow-400 fill-yellow-400" />
           <h1 className="font-bold tracking-[0.2em] text-sm text-slate-100">MOTION<span className="text-cyan-500">LAB</span></h1>
        </div>
        
        <div className={`px-3 py-1 rounded border text-[10px] font-bold tracking-widest transition-colors ${visionMode ? 'bg-cyan-950/50 border-cyan-500 text-cyan-400 shadow-[0_0_15px_rgba(34,211,238,0.2)]' : 'bg-slate-900 border-slate-700 text-slate-500'}`}>
          {visionMode ? '● SENSOR ACTIVE' : '○ SENSOR OFFLINE'}
        </div>
      </header>

      {/* Main Test Area */}
      <main className="flex-1 flex flex-col items-center justify-center relative z-10 p-6 gap-8">
        
        {/* Central Core */}
        <div className="relative group">
          
          {/* Decorative Rings */}
          <div className={`absolute -inset-8 rounded-full border border-cyan-500/10 ${visionMode ? 'animate-[spin_8s_linear_infinite]' : ''}`} />
          <div className={`absolute -inset-16 rounded-full border border-dashed border-cyan-500/5 ${visionMode ? 'animate-[spin_12s_linear_infinite_reverse]' : ''}`} />

          {/* Video Container */}
          <div className="relative w-[320px] h-[240px] bg-black rounded-xl overflow-hidden border-2 border-cyan-500/30 shadow-[0_0_50px_rgba(34,211,238,0.15)]">
             {/* The raw video feed */}
             <video 
               ref={videoRef} 
               className="absolute inset-0 w-full h-full object-cover opacity-60 mirror-mode scale-x-[-1]" 
               muted 
               playsInline 
             />
             
             {/* The visual debug overlay (Dots) */}
             <canvas 
                ref={debugCanvasRef} 
                width="320" 
                height="240"
                className="absolute inset-0 w-full h-full scale-x-[-1]" // Flip to match mirror video
             />

             {/* Hidden processing canvas */}
             <canvas ref={canvasRef} className="hidden" width="32" height="24" />
             
             {/* HUD Overlay Lines */}
             <div className="absolute inset-4 border border-cyan-500/20 rounded opacity-50 pointer-events-none">
                <div className="absolute top-1/2 left-0 w-2 h-[1px] bg-cyan-500" />
                <div className="absolute top-1/2 right-0 w-2 h-[1px] bg-cyan-500" />
                <div className="absolute top-0 left-1/2 w-[1px] h-2 bg-cyan-500" />
                <div className="absolute bottom-0 left-1/2 w-[1px] h-2 bg-cyan-500" />
             </div>
             
             {/* Center Status Text */}
             {!visionMode && (
                <div className="absolute inset-0 flex items-center justify-center bg-black/60 backdrop-blur-sm">
                   <button onClick={() => setVisionMode(true)} className="flex flex-col items-center gap-2 text-slate-400 hover:text-white transition-colors">
                      <Camera className="w-8 h-8" />
                      <span className="text-xs tracking-widest">ACTIVATE CAMERA</span>
                   </button>
                </div>
             )}
          </div>

          {/* Gesture Feedback Popups */}
          {gestureFeedback === 'left' && (
             <div className="absolute -left-32 top-1/2 -translate-y-1/2 flex items-center gap-2 animate-in slide-in-from-right-10 duration-200">
                <MoveHorizontal className="w-12 h-12 text-cyan-400 rotate-180 drop-shadow-[0_0_10px_rgba(34,211,238,0.8)]" />
                <span className="text-xl font-black italic text-cyan-100 bg-cyan-950/80 px-2 py-1 rounded">LEFT</span>
             </div>
          )}
          {gestureFeedback === 'right' && (
             <div className="absolute -right-32 top-1/2 -translate-y-1/2 flex items-center gap-2 flex-row-reverse animate-in slide-in-from-left-10 duration-200">
                <MoveHorizontal className="w-12 h-12 text-purple-400 drop-shadow-[0_0_10px_rgba(168,85,247,0.8)]" />
                <span className="text-xl font-black italic text-purple-100 bg-purple-950/80 px-2 py-1 rounded">RIGHT</span>
             </div>
          )}
        </div>

        {/* Real-time Metrics Dashboard */}
        <div className="w-full max-w-2xl bg-slate-900/50 border border-slate-800 rounded-2xl p-6 grid grid-cols-3 gap-8 items-end relative overflow-hidden backdrop-blur-sm">
           <div className="absolute top-0 left-0 w-full h-1 bg-gradient-to-r from-transparent via-cyan-500/20 to-transparent" />

           {/* Left Sensor Data */}
           <div className="text-center space-y-2">
              <div className="text-[10px] text-cyan-500/70 tracking-widest font-bold">LEFT SENSOR</div>
              <div className="h-24 bg-slate-950/50 rounded-lg relative overflow-hidden flex items-end justify-center border border-slate-800">
                 <div 
                   className="w-full bg-cyan-500/80 transition-all duration-75 ease-out shadow-[0_0_15px_rgba(34,211,238,0.3)]"
                   style={{ height: `${Math.min(100, motionStats.left)}%` }} 
                 />
                 <div className="absolute bottom-1 text-[10px] font-mono text-white mix-blend-difference">{Math.round(motionStats.left)}</div>
              </div>
           </div>

           {/* Sensitivity Control */}
           <div className="flex flex-col items-center justify-end h-full pb-2">
              <div className="mb-4 text-center">
                <div className="text-2xl font-bold text-white">{sensitivity}%</div>
                <div className="text-[10px] text-slate-500 tracking-wider">SENSITIVITY</div>
              </div>
              <input 
                type="range" 
                min="1" 
                max="100" 
                value={sensitivity} 
                onChange={(e) => setSensitivity(Number(e.target.value))}
                className="w-full h-2 bg-slate-800 rounded-lg appearance-none cursor-pointer accent-cyan-500 hover:accent-cyan-400 transition-all"
              />
              <p className="mt-3 text-[9px] text-slate-500 text-center leading-tight max-w-[150px]">
                 Move hand fast across the frame. Look for colored dots on video.
              </p>
           </div>

           {/* Right Sensor Data */}
           <div className="text-center space-y-2">
              <div className="text-[10px] text-purple-500/70 tracking-widest font-bold">RIGHT SENSOR</div>
              <div className="h-24 bg-slate-950/50 rounded-lg relative overflow-hidden flex items-end justify-center border border-slate-800">
                 <div 
                   className="w-full bg-purple-500/80 transition-all duration-75 ease-out shadow-[0_0_15px_rgba(168,85,247,0.3)]"
                   style={{ height: `${Math.min(100, motionStats.right)}%` }} 
                 />
                 <div className="absolute bottom-1 text-[10px] font-mono text-white mix-blend-difference">{Math.round(motionStats.right)}</div>
              </div>
           </div>

        </div>

      </main>

      <style>{`
        .mirror-mode {
          transform: scaleX(-1);
        }
      `}</style>
    </div>
  );
}
